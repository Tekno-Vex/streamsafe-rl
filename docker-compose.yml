services:
  # Redis - stores user history and channel velocity
  redis:
    image: redis:7-alpine
    container_name: streamsafe-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes --appendfsync everysec
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - streamsafe
    environment:
      - TZ=UTC

  # Zookeeper - required by Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    platform: linux/amd64
    container_name: streamsafe-zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
    networks:
      - streamsafe

  # Kafka - message queue for moderation events
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    platform: linux/amd64
    container_name: streamsafe-kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092,PLAINTEXT_HOST://0.0.0.0:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - streamsafe

  # Moderation Service - the core decision service
  moderation:
    build:
      context: ./moderation
      dockerfile: Dockerfile
    container_name: streamsafe-moderation
    depends_on:
      redis:
        condition: service_healthy
      kafka:
        condition: service_started
    ports:
      - "8000:8000"
    environment:
      # Redis configuration
      REDIS_URL: redis://redis:6379
      REDIS_TIMEOUT: "0.5"
      
      # Kafka configuration
      KAFKA_ENABLED: "true"
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      KAFKA_TOPIC: moderation-events
      
      # Logging
      LOG_LEVEL: INFO
      
      # Service metadata
      SERVICE_VERSION: "1.0.0"
      DEPLOYMENT_ENV: local
      
    volumes:
      # Mount logs directory for Parquet files persistence
      - ./moderation/logs:/app/logs
    networks:
      - streamsafe
    healthcheck:
      test: ["CMD", "python3", "-c", "import httpx; httpx.get('http://localhost:8000/health', timeout=5).raise_for_status()"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: unless-stopped
    command: python3 -m uvicorn app.api:app --host 0.0.0.0 --port 8000 --loop uvloop

    # Add this under 'services:'
  spark-job:
    image: jupyter/pyspark-notebook:latest
    volumes:
      - ./analytics:/home/jovyan/work
    command: start.sh python /home/jovyan/work/reward_job.py
    working_dir: /home/jovyan/work

volumes:
  redis_data:
    driver: local
  kafka_data:
    driver: local
  zookeeper_data:
    driver: local

networks:
  streamsafe:
    driver: bridge